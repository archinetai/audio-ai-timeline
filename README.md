# Audio AI Timeline

Here we will keep track of the latest AI models for audio generation, starting in 2023!

## 2023

| Date  | Release                                                                                                                                                                                      | Paper                                                                                    | Code                                                         | Trained Model                                                                                                                                                 |
| ----- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 30.01 | [SingSong: Generating musical accompaniments from singing](https://storage.googleapis.com/sing-song/index.html)                                                                                 | [arXiv](https://arxiv.org/abs/2301.12662)                                                   | -                                                            | -                                                                                                                                                             |
| 30.01 | [AudioLDM: Text-to-Audio Generation with Latent Diffusion Models](https://audioldm.github.io/)                                                                                                  | [arXiv](https://arxiv.org/abs/2301.12503)                                                   | *                                                            | -                                                                                                                                                             |
| 30.01 | [Mo√ªsai: Text-to-Music Generation with Long-Context Latent Diffusion](https://anonymous0.notion.site/Mo-sai-Text-to-Audio-with-Long-Context-Latent-Diffusion-b43dbc71caf94b5898f9e8de714ab5dc) | [arXiv](https://arxiv.org/abs/2301.11757)                                                   | [GitHub](https://github.com/archinetai/audio-diffusion-pytorch) | -                                                                                                                                                             |
| 29.01 | [Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models](https://text-to-audio.github.io/)                                                                               | [PDF](https://text-to-audio.github.io/paper.pdf)                                            | -                                                            | -                                                                                                                                                             |
| 28.01 | [Noise2Music](https://noise2music.github.io/)                                                                                                                                                   | -                                                                                        | -                                                            | -                                                                                                                                                             |
| 27.01 | [RAVE2](https://twitter.com/antoine_caillon/status/1618959533065535491?s=20&t=jMkPWBFuAH19HI9m5Sklmg)                                                                                           | [arXiv](https://arxiv.org/abs/2111.05011)                                                   | [GitHub](https://github.com/acids-ircam/RAVE)                   | -                                                                                                                                                             |
| 26.01 | [MusicLM: Generating Music From Text](https://google-research.github.io/seanet/musiclm/examples/)                                                                                               | [arXiv](https://arxiv.org/abs/2301.11325)                                                   | -                                                            | -                                                                                                                                                             |
| 22.01 | [Dance2MIDI: Dance-Driven Multi-Instruments Music Generation](https://dance2midi.github.io/)                                                                                                    | [arXiv](https://arxiv.org/abs/2301.09080)                                                   | [GitHub](https://github.com/Dance2MIDI/Dance2MIDI)              | -                                                                                                                                                             |
| 18.01 | [Msanii: High Fidelity Music Synthesis on a Shoestring Budget](https://kinyugo.github.io/msanii-demo/)                                                                                          | [arXiv](https://arxiv.org/abs/2301.06468)                                                   | [GitHub](https://github.com/Kinyugo/msanii)                     | [Hugging Face](https://huggingface.co/spaces/kinyugo/msanii) [Colab](https://colab.research.google.com/github/Kinyugo/msanii/blob/main/notebooks/msanii_demo.ipynb) |
| 16.01 | [ArchiSound: Audio Generation with Diffusion](https://flavioschneider.notion.site/Audio-Generation-with-Diffusion-c4f29f39048d4f03a23da13078a44cdb)                                             | [PDF](https://github.com/flavioschneider/master-thesis/raw/main/audio_diffusion_thesis.pdf) | [GitHub](https://github.com/archinetai/audio-diffusion-pytorch) | -                                                                                                                                                             |
| 05.01 | [VALL-E: Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers](https://valle-demo.github.io/)                                                                                 | [arXiv](https://arxiv.org/abs/2301.02111)                                                   | -                                                            | -                                                                                                                                                             |
